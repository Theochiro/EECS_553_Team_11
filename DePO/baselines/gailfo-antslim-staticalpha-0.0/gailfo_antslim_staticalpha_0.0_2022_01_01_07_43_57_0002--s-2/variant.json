{
  "adv_irl_params": {
    "disc_lr": 0.0003,
    "disc_momentum": 0.9,
    "disc_optim_batch_size": 256,
    "eval_deterministic": true,
    "eval_no_terminal": false,
    "freq_saving": 20,
    "grad_pen_weight": 0.5,
    "max_path_length": 1000,
    "min_steps_before_training": 5000,
    "mode": "gail2",
    "no_terminal": true,
    "num_disc_updates_per_loop_iter": 1,
    "num_epochs": 202,
    "num_policy_updates_per_loop_iter": 1,
    "num_steps_between_train_calls": 1000,
    "num_steps_per_epoch": 10000,
    "num_steps_per_eval": 20000,
    "num_update_loops_per_train_call": 1000,
    "policy_optim_batch_size": 256,
    "policy_optim_batch_size_from_expert": 0,
    "replay_buffer_size": 20000,
    "save_algorithm": false,
    "save_best": true,
    "save_environment": false,
    "save_replay_buffer": false,
    "state_only": true,
    "use_grad_pen": true,
    "wrap_absorbing": false
  },
  "description": "Train an adversarial IRL lfo model",
  "disc_clamp_magnitude": 10.0,
  "disc_hid_act": "tanh",
  "disc_hid_dim": 128,
  "disc_num_blocks": 2,
  "disc_use_bn": false,
  "env_specs": {
    "env_kwargs": {},
    "env_name": "ant",
    "eval_env_seed": 2,
    "training_env_seed": 2
  },
  "exp_id": 2,
  "exp_name": "gailfo_antslim_staticalpha_0.0",
  "expert_idx": 0,
  "expert_name": "ant_slim_sac",
  "mem_per_worker": "4gb",
  "node_exclusions": "gpu048,gpu024,gpu025,gpu012,gpu027",
  "num_cpu_per_worker": 32,
  "num_gpu_per_worker": 1,
  "num_workers": 3,
  "partitions": "cpu",
  "policy_net_size": 256,
  "policy_num_hidden_layers": 2,
  "sac_params": {
    "alpha": 0.0,
    "beta_1": 0.25,
    "discount": 0.99,
    "policy_lr": 0.0003,
    "policy_mean_reg_weight": 0.001,
    "policy_std_reg_weight": 0.001,
    "qf_lr": 0.0003,
    "reward_scale": 2.0,
    "soft_target_tau": 0.005,
    "train_alpha": false
  },
  "scale_env_with_demo_stats": false,
  "script_path": "run_scripts/adv_irl_exp_script.py",
  "seed": 2,
  "traj_num": 4
}